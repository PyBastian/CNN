{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVQu6vihr_J"
      },
      "source": [
        "<center><img src=\"data:image/png;base64,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\" title=\"Title text\" /></center>\n",
        "\n",
        "\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477/577 Redes Neuronales Artificiales - 2022-2 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 2: Grape disease detection  </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "* Carga de datos y preprocesamientos\n",
        "* Convoluciones y parámetros\n",
        "* Profundidad\n",
        "* Image Data Augmentation\n",
        "* Bloque Residual\n",
        "* Bloque Inception\n",
        "* Transfer Learning\n",
        "\n",
        "\n",
        "**Formalidades**  \n",
        "* Equipos de trabajo de 3 personas (*Los estudiantes deben estar preparados para presentar la tarea el día de la entrega*).\n",
        "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos), se penalizará fuertemente ausencia de comentarios, explicaciones de gráficos, _etc_. Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
        "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
        "* Formato de entrega: envı́o de link del repositorio en _Github_, al correo electrónico de los ayudantes (<maryon.morales@sansano.usm.cl>, <sebastian.sanchezl@sansano.usm.cl>), en copia al profesor (<cvalle@inf.utfsm.cl>). Especificar el siguiente asunto: [INF-395/477/577-2022-2 Tarea 2]. Invitar como colaborador a los usuarios de github \"ssanchezl\" y \"maryonmorales\" para poder acceder al repositorio en caso de ser privado.\n",
        "\n",
        "* Fecha de presentaciones 11 de Noviembre, en horario de clases.\n",
        "* Fecha de entrega: 12 de Noviembre. Hora límite de entrega: 12:00 p.m. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail igualmente.\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo, **solo son guias** y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
        "Recuerden intercalar su código con *comentarios* en celdas _Markdown_, con los comentarios de la pregunta y con cualquier análisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. *No respondan las preguntas en comentarios en el código*.\n",
        "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará tanto la elección en si, sino que la argumentación detrás de la elección será lo más ponderado.\n",
        "Si algún modelo se demora demasiado en correr en su máquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, incluso con la opción de aceleración con GPU (particularmente útil para los modelos más grandes), esto puede ser relevante para las máquinas más lentas al momento de realizar exploraciones con _K-folds_ o las redes más grandes. Existe también la posibilidad de utilizar _Google Cloud Plataform_ o _Amazon Web Service_, donde tienen máquinas aceleradas con GPU; maquinas ya configuradas para _deep leraning_ pueden encontrarse en el _Marketplace_ de cada proveedor de servicios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LcJ7Zop5pB"
      },
      "source": [
        "## 1 - Redes Convolucionales para la detección de enfermedades en la uva.\n",
        "\n",
        "### Información y anexos\n",
        "\n",
        "En esta oportunidad se trabajará con un conjunto de imágenes de hojas de las plantas de uva y la tarea será identificar cuál de las 3 enfermedades esta presente en la plante o si esta sana, a partir de las imágenes entregadas. A continuación se presentan 4 sitios en para encontrar más información acerca de las enfermedades de las uvas, de las cuales se trabajará con las últimas 3 listadas:\n",
        "\n",
        "- [Diseases of Grape (Vitis spp.)](https://web.archive.org/web/20080223134516/http://www.apsnet.org/online/common/names/grape.asp)\n",
        "\n",
        "- [Black rot](http://ipm.illinois.edu/diseases/series700/rpd703/)\n",
        "\n",
        "- [Black Measles](https://ieeexplore.ieee.org/document/9397205)\n",
        "\n",
        "- [Isariopsis leaf spot](http://horticulturejournal.usamv.ro/pdf/2017/Art33.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLFE6XMBrHFe"
      },
      "source": [
        "## Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yp-gNGw_rQ88"
      },
      "outputs": [],
      "source": [
        "import zipfile as zf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import filecmp as fcmp\n",
        "import os\n",
        "import scipy as sp\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import gradient_descent_v2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import History, EarlyStopping\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM0-egcQpruh"
      },
      "source": [
        "## 1.a Carga de datos y visualizaciones\n",
        "\n",
        "Establezca la ubicación de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r-P3WqRIpnwZ"
      },
      "outputs": [],
      "source": [
        "data_dir  = \"\"\n",
        "data_zip_path = data_dir + 'Grape.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDkBkh2f4kkP"
      },
      "source": [
        "Descomprima los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "49dQ94HY8p-f"
      },
      "outputs": [],
      "source": [
        "with zf.ZipFile(data_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "data_dir_Grapes = data_dir+ 'Grape'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1y_agom4nbu"
      },
      "source": [
        "Revise las imágenes de cada carpeta y cargue las imágenes en un arreglo $X$, el nombre de la carpeta indica el nombre de cada clase $y$. Cargue los nombres de las clases en un arreglo de tal forma que cada imagen $X$ esté asociada a su respectiva clase $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3hfbltnw-8zD"
      },
      "outputs": [],
      "source": [
        "X = list()\n",
        "y = list()\n",
        "\n",
        "for dirname, _, filenames in os.walk(data_dir_Grapes):           \n",
        "    for filename in filenames: \n",
        "        image = Image.open(os.path.join(dirname, filename))\n",
        "        X.append(np.array(image, dtype=np.uint8))\n",
        "        y.append(dirname)   \n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8aj_x1JagOW"
      },
      "source": [
        "### ¿Qué porcentaje del total de imagenes tiene cada clase? ¿Están balanceadas las clases?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma422awte3MV",
        "outputId": "d5fd25c9-6ab4-4980-b641-1db171e30277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per class count:\n",
            "Grape\\Grape___Black_rot: 1180 (29.05%)\n",
            "Grape\\Grape___Esca_(Black_Measles): 1383 (34.05%)\n",
            "Grape\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1076 (26.49%)\n",
            "Grape\\Grape___healthy: 423 (10.41%)\n"
          ]
        }
      ],
      "source": [
        "print('Per class count:')\n",
        "for cls, n in zip(*np.unique(y, return_counts=True)):\n",
        "    print(f'{cls}: {n} ({(n/float(len(y)))*100:.2f}%)')\n",
        "#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Como podemos observar la clasa sana posee la menor cantidad de data, siendo esta un posible problemaº**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u53ULY2p8Xog"
      },
      "source": [
        "### Visualice algunas imágenes de cada una de las clases junto con sus nombres y revise sus dimensiones y tipo de dato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "tLhhNBssRsPC",
        "outputId": "276e068b-78e2-4bd6-f952-114ce7f7abc4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams[\"figure.figsize\"]=[8,8]\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(y[0])\n",
        "plt.imshow(Image.fromarray(X[0]))\n",
        " \n",
        "# ...\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_teku39XYpKu"
      },
      "source": [
        "## 1.b Preprocesamiento\n",
        "\n",
        "Transforme $y$ a encoding one hot vector, para esto utilice la librería de SciKit Learn. OneHotEncoder recibe valores categóricos numéricos, por lo que las clases en formato string deben ser transformados vía Label Encoding antes de aplicar One Hot Encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gowwWuWdor3"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uW8VL5zS7Ui",
        "outputId": "996d0cee-f19d-403d-8044-e4e81202dafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 2 2 2]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{0: 1180, 1: 1383, 2: 1076, 3: 423}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating instance of labelencoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the transformer\n",
        "le.fit(y)\n",
        "y_le = le.transform(y)\n",
        "print(y_le)\n",
        "unique, counts = np.unique(y_le, return_counts=True)\n",
        "dict(zip(unique, counts))\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49rzbGiodt9z"
      },
      "source": [
        "### OneHotEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UAxoOKY8dxmp"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "# Creating instance of onehotencoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "y_le = y_le.reshape(len(y_le), 1)\n",
        "# Fit the transformer\n",
        "\n",
        "# define example\n",
        "y_ohe = to_categorical(y_le)\n",
        "\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shIvuW4-N9nk"
      },
      "source": [
        "### Conjuntos de datos\n",
        "Separe los datos en conjuntos de entrenamiento, validación y prueba. Elija un porcentaje para separar los conjuntos y justifique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1yM5Pq47DNEv"
      },
      "outputs": [],
      "source": [
        "sf = StratifiedShuffleSplit(n_splits=10, test_size=0.10, random_state=42)\n",
        "\n",
        "\n",
        "for train_index, val_index in sf.split(X, y_ohe):\n",
        "    X_train, X_test = X[train_index], X[val_index]\n",
        "    y_train, y_test = y_ohe[train_index], y_ohe[val_index]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A9xo7pW7DOW6"
      },
      "outputs": [],
      "source": [
        "sf2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in sf2.split(X_train, y_train):\n",
        "    X_train, X_val = X_train[train_index], X_train[test_index]\n",
        "    y_train, y_val = y_train[train_index], y_train[test_index]  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Se eligio un 10% de test data y del restante 90%, se utilizara un 20% para validación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkinJCfD0pgS"
      },
      "source": [
        "### Normalización de los datos\n",
        "\n",
        "Por ahora los valores de los píxeles de las imágenes se encuentran en el rango $[0,255]$. Normalice cada canal RGB por separado y obtenga $\\langle(\\mu_R,\\sigma^2_R), (\\mu_G,\\sigma^2_G), (\\mu_B,\\sigma^2_B)\\rangle_\\text{Train Set}$ y luego use estos parámetros para normalizar los 3 conjuntos separados en la preguna anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ata9mUkvm8ep"
      },
      "outputs": [],
      "source": [
        "# Perform Standarization\n",
        "def prep_normalize(X_train, X_val, X_test):\t\n",
        "\t\t\n",
        "\t\tx_means = X_train.mean(axis=(0,1,2), keepdims=True)\n",
        "\t\tx_std = X_train.std(axis=(0,1,2), keepdims=True)\n",
        "\t\n",
        "\t\t# r_mean = (np.mean(X_train[:][:][:][0]))\n",
        "\t\t# r_std = (np.std(X_train[:][:][:][0]))\n",
        "\t\n",
        "\t\t# g_mean = (np.mean(X_train[:][:][:][1]))\n",
        "\t\t# g_std = (np.std(X_train[:][:][:][1]))\n",
        "\t\n",
        "\t\t# b_mean = (np.mean(X_train[:][:][:][2]))\n",
        "\t\t# b_std = (np.std(X_train[:][:][:][2]))\n",
        "\t\t# for value in range(len((X_train[:][:][:][0]))):\n",
        "\t\t# \tX_train[:][:][:][value] = X_train[:][:][:][value] - r_mean\n",
        "\t\tX_train\t= ((X_train - x_means) / x_std).astype(np.float32)\n",
        "\t\tX_val   = ((X_val - x_means) / x_std).astype(np.float32)\n",
        "\t\tX_test  = ((X_test - x_means) / x_std).astype(np.float32)\n",
        "\t\t# print(X_train[0])\n",
        "\n",
        "\t\t# Standarize each channel separately.\n",
        "\t\treturn X_train, X_val, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cWDaDu9D9ONn"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test = prep_normalize(X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbd8RX2xSJUq"
      },
      "source": [
        "## 1.c Primera Red Convolucional\n",
        "\n",
        "Entrenaremos una primera red convolucional sobre los datos, con la mayoría de los parámetros por defecto. Cree primero una red con la siguiente la estructura $C \\times P \\times C \\times P \\times D\\times D$, donde $C$ representa una capa convolucional, $P$ una capa Max Pooling y $D$ una capa densa. Note que antes de la capa densa debe agregar una capa Flatten que transforma los filtros a vectores que luego pueden ser utilizados por la capa densa.\n",
        "\n",
        "Para los parámetros de las capas, fijaremos ambas capas convolucionales con 128 filtros de $3 \\times 3$, stride por default de $1 \\times 1$, y padding \"same\", es decir, agregaremos $0$ a los bordes de la imágen de tal manera que se preserve la dimension de la imágen al atravesar la capa, las capas de pooling tendrán tamaño y stride $2\\times 2$, como muentra el código. \n",
        "\n",
        "Utilice el método `.summary` del modelo para ver la cantidad de parámetros y las dimensiones de los outputs de cada capa. Justifique el número de parámetros y el Output Shape de cada capa en función de la estructura de la red y lo aprendido en clase.\n",
        "\n",
        "Preguntas:\n",
        "\n",
        "Investigue y explique qué es el stride en la capa convolucional, ¿Qué operación efectúa la activación SoftMax y qué representaría en términos del problema el vector de salida de la red?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5jLEuYPhRUy2"
      },
      "outputs": [],
      "source": [
        "def baseline_model(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnqKv3PaIaYF"
      },
      "source": [
        "Compile la red definida en el item anterior. Para esta pregunta puede usar la activación, el optimizador, learning rate y learning rate decay que usted desee con sus respectivos argumentos, justificando su elección, y debe usar como loss Categorical Crossentropy.\n",
        "\n",
        "Entrene la red hasta observar convergencia recuperando su history. Grafique como varía el accuracy en entrenamiento y validación a lo largo del aprendizaje. Adicionalmente obtenga el accuracy para todo el conjunto de test.\n",
        "\n",
        "Preguntas: ¿Por qué preferimos medir crossentropy y no por ejemplo MSE en este problema?¿Qué valor representa el accuracy?, ¿Le parece buena medida de desempeño para este problema?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = Input(shape=X_train.shape[1:])\n",
        "num_classes = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiR0SsEWIefO",
        "outputId": "48398ca8-a715-45b8-b99d-4a935d4d8655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "293/293 [==============================] - 367s 1s/step - loss: 1.0527 - accuracy: 0.6987 - val_loss: 0.4629 - val_accuracy: 0.8372\n",
            "Epoch 2/5\n",
            "293/293 [==============================] - 365s 1s/step - loss: 0.3673 - accuracy: 0.8772 - val_loss: 0.3111 - val_accuracy: 0.8824\n",
            "Epoch 3/5\n",
            "293/293 [==============================] - 355s 1s/step - loss: 0.1864 - accuracy: 0.9326 - val_loss: 0.3258 - val_accuracy: 0.8769\n",
            "Epoch 4/5\n",
            "293/293 [==============================] - 408s 1s/step - loss: 0.1754 - accuracy: 0.9432 - val_loss: 0.5077 - val_accuracy: 0.8372\n",
            "Epoch 5/5\n",
            "293/293 [==============================] - 330s 1s/step - loss: 0.0941 - accuracy: 0.9709 - val_loss: 0.3247 - val_accuracy: 0.8947\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# build the model\n",
        "model = baseline_model(inputs,num_classes)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p_IiB-oXaPDq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams[\"figure.figsize\"]=[14,4]\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label=\"Training accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Validation accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FvYfW7AqhgnW"
      },
      "outputs": [],
      "source": [
        "# Test evaluation of the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZSsjXpDfm0Vz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.31404876708984375\n",
            "Accuracy in test data: 0.9041768908500671\n"
          ]
        }
      ],
      "source": [
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp7MviNiHtU8"
      },
      "source": [
        "## 1.d Parámetros de la capa Convolucional\n",
        "\n",
        "Entrene la misma red (arquitectura $C\\times P\\times C\\times P\\times D\\times D$) de la pregunta anterior. A continuación en cada punto debe probar las variaciones que se le indican, manteniendo el resto tal como estaba. Por ejemplo si está probando distintos números de filtros, solo se modifica el número de filtros; si está probando distintos kernel size, entonces el número de filtros volverá a fijarse en 128 como estaba en la pregunta anterior.\n",
        "\n",
        "+ filters (pruebe 2 números, ej: 512, 32),\n",
        "+ kernel_size (pruebe $1\\times 1$, $5\\times 5$, $7\\times 7$ y $9\\times 9$),\n",
        "+ strides (pruebe (2,2) y (3,3))\n",
        "+ padding (pruebe valid),\n",
        "+ dilation_rate (pruebe 1,2,3)\n",
        "+ MaxPooling y AveragePooling (en ambos casos pruebe stride de (3,3), (5,5))\n",
        "+ Dense (pruebe con 2 capas densas con 2 números de neuronas distintos en cada capa (sin contar la de salida softmax de 4 clases), por ejemplo: \n",
        "$$\\cdots \\times D(units=64)\\times D(units=32)\\times D(\\text{num_clases}, ``softmax\"),$$\n",
        "$$\\cdots \\times D(units=128)\\times D(units=8)\\times D(\\text{num_clases}, ``softmax\"),$$\n",
        "$$\\cdots \\times D(units=256)\\times D(\\text{num_clases}, ``softmax\"),$$\n",
        "$$\\cdots \\times D(units=16)\\times D(\\text{num_clases}, ``softmax\").$$\n",
        "\n",
        "Lea la documentación de esta herramienta e investigue cuales de estos parámetros se pueden combinar para realizar una búsqueda en grilla (¿Qué es una búsqueda en grilla?) y cuales no son compatibles entre ellos para ciertos valores, explique por qué.\n",
        "\n",
        "Formule la dimensión de salida $(H_{out}, W_{out})$ en función de la dimensión de entrada $(H_{in}, W_{in})$, el tamaño del kernel $k$, el stride $s$, el padding $p$ y el dilation_rate $d$.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funciones Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XssvAMZh-rIf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikeras) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\basti\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.8.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LtJdLZCxDmf6"
      },
      "outputs": [],
      "source": [
        "import keras_tuner \n",
        "import scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ke5SftLFzV0A"
      },
      "outputs": [],
      "source": [
        "def model11(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 64,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 64,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Wdvv43hozeUZ"
      },
      "outputs": [],
      "source": [
        "def model12(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 32,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 32,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yemRk3lgzh60"
      },
      "outputs": [],
      "source": [
        "def model21(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (1,1),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (1,1),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model22(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (5,5),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (5,5),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model23(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (7,7),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (7,7),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model24(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (9,9),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (9,9),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model31(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(2, 2),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(2, 2),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model32(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(2, 2),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(3, 3),\n",
        "                    padding = 'same',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model41(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'valid',\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'valid',\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model51(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model52(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=2,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=2,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model53(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=3,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=3,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import AveragePooling2D\n",
        "def model61(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = AveragePooling2D(pool_size = (3,3))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = AveragePooling2D(pool_size = (3,3))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model62(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = AveragePooling2D(pool_size = (5,5))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = AveragePooling2D(pool_size = (5,5))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "\n",
        "    dense2 = Dense(units=num_classes, activation='softmax')(dense1 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense2)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model72(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "    dense2 = Dense(units=16, activation='relu')(dense1)\n",
        "\n",
        "    dense3 = Dense(units=num_classes, activation='softmax')(dense2 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense3)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model72(inputs,num_classes):    \n",
        "    x = inputs\n",
        "    # create model    \n",
        "    conv1  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = 128,\n",
        "                    kernel_size = (3,3),\n",
        "                    strides=(1, 1),\n",
        "                    padding = 'same',\n",
        "                    dilation_rate=1,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "\n",
        "    dense1 = Dense(units=64, activation='relu')(Flatten()(pool2))    \n",
        "    dense2 = Dense(units=32, activation='relu')(dense1)\n",
        "\n",
        "    dense3 = Dense(units=num_classes, activation='softmax')(dense2 )\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense3)    \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7meSbqRRZ0tO"
      },
      "outputs": [],
      "source": [
        "# def baseline_model(inputs,num_classes):    \n",
        "#     x = inputs\n",
        "#     conv1  = Conv2D(filters = 128,\n",
        "#                     kernel_size = (3,3),\n",
        "#                     strides=(1, 1),\n",
        "#                     padding = 'same',\n",
        "#                     activation = 'relu',\n",
        "#                     data_format=\"channels_last\")(x)\n",
        "\n",
        "#     pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "#     conv2  = Conv2D(filters = 128,\n",
        "#                     kernel_size = (3,3),\n",
        "#                     strides=(1, 1),\n",
        "#                     padding = 'same',\n",
        "#                     activation = 'relu')(pool1)\n",
        "#     pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "#     dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "#     dense2 = Dense(units=num_classes, activation='softmax')( )\n",
        "#     model  = Model(inputs = inputs, outputs = dense2)    \n",
        "#     return model\n",
        "\n",
        "\n",
        "def p_model(filters=128, kernel_size=(3,3), strides=(1,1), padding='same',dilation_rate=1,pool_size=(2,2)):\n",
        "    x = inputs\n",
        "    conv1  = Conv2D(filters = filters,kernel_size = kernel_size,\n",
        "                    strides=strides,\n",
        "                    padding = 'same',\n",
        "                    dilation_rate = dilation_rate,\n",
        "                    activation = 'relu',\n",
        "                    data_format=\"channels_last\")(x)\n",
        "\n",
        "    pool1  = MaxPooling2D(pool_size = pool_size)(conv1)\n",
        "\n",
        "    conv2  = Conv2D(filters = filters,\n",
        "                    kernel_size = kernel_size,\n",
        "                    dilation_rate = dilation_rate,\n",
        "                    strides=strides,\n",
        "                    padding = padding,\n",
        "                    activation = 'relu')(pool1)\n",
        "\n",
        "    pool2  = MaxPooling2D(pool_size = pool_size)(conv2)    \n",
        "\n",
        "    dense_I = Dense(units=32, activation='relu')(Flatten()(pool2))     \n",
        "    \n",
        "    dense_O = Dense(units=4, activation='softmax')(dense_I)\n",
        "\n",
        "    model  = Model(inputs = inputs, outputs = dense_O)  \n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5cWWS3XTMew5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "filters (pruebe 2 números, ej: 512, 32),\n",
        "kernel_size (pruebe  1×1 ,  5×5 ,  7×7  y  9×9 ),\n",
        "strides (pruebe (2,2) y (3,3))\n",
        "padding (pruebe valid),\n",
        "dilation_rate (pruebe 1,2,3)\n",
        "MaxPooling y AveragePooling (en ambos casos pruebe stride de (3,3), (5,5))\n",
        "\n",
        "'''\n",
        "\n",
        "inputs = Input(shape=X_train.shape[1:])\n",
        "num_classes = 4\n",
        "\n",
        "ann = KerasClassifier(model=p_model,filters=32,kernel_size=(3,3), strides=(1,1), padding='same',dilation_rate=1,pool_size=(2,2))\n",
        "\n",
        "# Create hyperparameter space\n",
        "filters =[32,64,128]\n",
        "kernel_size = [(3,3),(5,5),(7,7),(9,9)]\n",
        "strides =[(2,2),(3,3)]\n",
        "padding = ['valid','same']\n",
        "dilation_rate = [1,2,3]\n",
        "pool_size =[(3,3),(5,5)]\n",
        "\n",
        "# Create hyperparameter options\n",
        "\n",
        "#  padding=padding,dilation_rate=dilation_rate,pool_size=pool_size, kernel_size=kernel_size, strides=strides\n",
        "hyperparameters = dict(filters=filters)\n",
        "\n",
        "# Create grid search\n",
        "# cv=5 is the default 5-fold\n",
        "grid = GridSearchCV(estimator=ann, cv=2,n_jobs = 1, param_grid=hyperparameters)\n",
        "\n",
        "# grid_result = grid.fit(X_train, y_train)\n",
        "# best_params=grid_result.best_params_\n",
        "# accuracy=grid_result.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uBdSxhUPRB1P"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for caso in params:\n",
        "\n",
        "#     # build the model\n",
        "#     model = p_model(params)\n",
        "\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\" ,restore_best_weights = True)]\n",
        "\n",
        "#     # Fit the model\n",
        "#     history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 179s 367ms/step - loss: 0.6823 - accuracy: 0.7596 - val_loss: 0.3218 - val_accuracy: 0.8824\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 169s 347ms/step - loss: 0.2973 - accuracy: 0.8991 - val_loss: 0.2757 - val_accuracy: 0.8974\n"
          ]
        }
      ],
      "source": [
        "model11 = model11(inputs,num_classes)\n",
        "\n",
        "model11.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history11 = model11.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.24566158652305603\n",
            "Accuracy in test data: 0.9115478992462158\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model11.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 83s 169ms/step - loss: 0.6625 - accuracy: 0.7685 - val_loss: 0.3603 - val_accuracy: 0.8878\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 82s 168ms/step - loss: 0.2513 - accuracy: 0.9142 - val_loss: 0.2202 - val_accuracy: 0.9289\n"
          ]
        }
      ],
      "source": [
        "model12 = model12(inputs,num_classes)\n",
        "\n",
        "model12.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history12 = model12.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.2399587780237198\n",
            "Accuracy in test data: 0.9238329529762268\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model12.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 212s 434ms/step - loss: 0.8020 - accuracy: 0.8263 - val_loss: 0.2839 - val_accuracy: 0.8960\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 207s 424ms/step - loss: 0.1736 - accuracy: 0.9425 - val_loss: 0.2259 - val_accuracy: 0.9179\n"
          ]
        }
      ],
      "source": [
        "model21 = model21(inputs,num_classes)\n",
        "\n",
        "model21.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history21 = model21.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.19260071218013763\n",
            "Accuracy in test data: 0.9312039017677307\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model21.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 744s 2s/step - loss: 1.4851 - accuracy: 0.3334 - val_loss: 1.3376 - val_accuracy: 0.3406\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 759s 2s/step - loss: 1.3296 - accuracy: 0.3403 - val_loss: 1.3228 - val_accuracy: 0.3406\n"
          ]
        }
      ],
      "source": [
        "model22 = model22(inputs,num_classes)\n",
        "\n",
        "model22.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history22 = model22.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 1.322156310081482\n",
            "Accuracy in test data: 0.34152334928512573\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model22.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 1402s 3s/step - loss: 1.4072 - accuracy: 0.4730 - val_loss: 1.0830 - val_accuracy: 0.5417\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 1367s 3s/step - loss: 0.9865 - accuracy: 0.5575 - val_loss: 1.0743 - val_accuracy: 0.5513\n"
          ]
        }
      ],
      "source": [
        "model23 = model23(inputs,num_classes)\n",
        "\n",
        "model23.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history23 = model23.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model23.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 1892s 4s/step - loss: 2.3871 - accuracy: 0.3365 - val_loss: 1.3145 - val_accuracy: 0.3406\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 1888s 4s/step - loss: 1.3148 - accuracy: 0.3403 - val_loss: 1.3136 - val_accuracy: 0.3406\n"
          ]
        }
      ],
      "source": [
        "model24 = model24(inputs,num_classes)\n",
        "\n",
        "model24.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history24 = model24.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 1.3126767873764038\n",
            "Accuracy in test data: 0.34152334928512573\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model24.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 61s 124ms/step - loss: 0.5822 - accuracy: 0.7661 - val_loss: 0.3814 - val_accuracy: 0.8386\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 59s 121ms/step - loss: 0.2465 - accuracy: 0.9060 - val_loss: 0.2187 - val_accuracy: 0.9179\n"
          ]
        }
      ],
      "source": [
        "model31 = model31(inputs,num_classes)\n",
        "\n",
        "model31.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history31 = model31.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.20318789780139923\n",
            "Accuracy in test data: 0.9385749101638794\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model31.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 47s 95ms/step - loss: 0.4774 - accuracy: 0.8020 - val_loss: 0.2783 - val_accuracy: 0.8974\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 46s 94ms/step - loss: 0.2373 - accuracy: 0.9090 - val_loss: 0.2289 - val_accuracy: 0.9097\n"
          ]
        }
      ],
      "source": [
        "model32 = model32(inputs,num_classes)\n",
        "\n",
        "model32.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history32 = model32.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.1890241950750351\n",
            "Accuracy in test data: 0.9336609244346619\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model32.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 336s 688ms/step - loss: 0.7996 - accuracy: 0.7096 - val_loss: 0.5359 - val_accuracy: 0.8276\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 337s 690ms/step - loss: 0.3171 - accuracy: 0.8841 - val_loss: 0.4581 - val_accuracy: 0.8482\n"
          ]
        }
      ],
      "source": [
        "model41 = model41(inputs,num_classes)\n",
        "\n",
        "model41.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history41 = model41.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.40417206287384033\n",
            "Accuracy in test data: 0.8673218488693237\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model41.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "488/488 [==============================] - 349s 714ms/step - loss: 1.0560 - accuracy: 0.5923 - val_loss: 1.0661 - val_accuracy: 0.6033\n",
            "Epoch 2/2\n",
            "488/488 [==============================] - 348s 714ms/step - loss: 0.6781 - accuracy: 0.7483 - val_loss: 0.6643 - val_accuracy: 0.7360\n"
          ]
        }
      ],
      "source": [
        "model51 = model51(inputs,num_classes)\n",
        "\n",
        "model51.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history51 = model51.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.5964989066123962\n",
            "Accuracy in test data: 0.7665847539901733\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model51.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model52 = model52(inputs,num_classes)\n",
        "\n",
        "model52.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history52 = model52.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model52.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model53 = model53(inputs,num_classes)\n",
        "\n",
        "model53.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history53 = model53.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model53.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model61 = model61(inputs,num_classes)\n",
        "\n",
        "model61.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history61 = model61.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model61.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model62 = model62(inputs,num_classes)\n",
        "\n",
        "model62.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history62 = model62.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model62.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlOPggdZNgVv"
      },
      "source": [
        "## 1.e Bloque $C\\times C\\times P$\n",
        "\n",
        "Cree y entrene redes utilizando *bloques* $C\\times C\\times P$ (dos capas convolucionales seguida de una de maxpool) y luego dos capas densas, por ejemplo la estructura de una red de 2 *bloques* sería la siguiente: $\\underbrace{C\\times C\\times P}_{\\text{bloque 1}} \\times \\underbrace{C\\times C\\times P}_{\\text{bloque 2}}\\times D \\times D$. Puede agregar las capas densas que desee basandose en la experiencia de las preguntas anteriores o lo aprendido en clases (justifique).\n",
        "\n",
        "La idea es explorar qué ocurre a medida que se modifica la profundidad de la red. Para esto, entrene redes con distintos números de *bloques*. Debe a lo menos entrenar una red por cada número de *bloques*: entre 1 y 5 *bloques*.\n",
        "\n",
        "Comente sobre los dos casos extremos (1 y 5 *bloques*), ¿le parece que alguno de los dos sea buena aproximación para la clasificación de estas imágenes? Para cada red recupere history y grafique los valores de accuracy en entrenamiento y validación.\n",
        "\n",
        "Quedan a su discreción los parámetros de cada capa convolucional, sin embargo, para el número de filtros en las capas convolucionales se recomienda disminuir el número de filtros por la mitad en cada *bloque* por ejemplo: $C(filters=128)\\times C(filters=128)\\times P \\times C(filters=64)\\times C(filters=64)\\times P\\times \\cdots \\times D \\times \\cdots \\times D.$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL7T7oW0AwVP"
      },
      "outputs": [],
      "source": [
        "# def baseline_model(inputs,num_classes):    \n",
        "#     x = inputs\n",
        "#     conv1  = Conv2D(filters = 128,\n",
        "#                     kernel_size = (3,3),\n",
        "#                     strides=(1, 1),\n",
        "#                     padding = 'same',\n",
        "#                     activation = 'relu',\n",
        "#                     data_format=\"channels_last\")(x)\n",
        "\n",
        "#     pool1  = MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "#     conv2  = Conv2D(filters = 128,\n",
        "#                     kernel_size = (3,3),\n",
        "#                     strides=(1, 1),\n",
        "#                     padding = 'same',\n",
        "#                     activation = 'relu')(pool1)\n",
        "#     pool2  = MaxPooling2D(pool_size = (2,2))(conv2)    \n",
        "#     dense1 = Dense(units=32, activation='relu')(Flatten()(pool2))    \n",
        "#     dense2 = Dense(units=num_classes, activation='softmax')( )\n",
        "#     model  = Model(inputs = inputs, outputs = dense2)    \n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_QAIhfsxZ1-5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "585/585 [==============================] - 1669s 3s/step - loss: 1.0475 - accuracy: 0.5137 - val_loss: 0.5586 - val_accuracy: 0.7784\n",
            "Epoch 2/2\n",
            "585/585 [==============================] - 1690s 3s/step - loss: 0.3502 - accuracy: 0.8663 - val_loss: 0.2153 - val_accuracy: 0.9234\n",
            "Loss in test data: 0.19792187213897705\n",
            "Accuracy in test data: 0.9262899160385132\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "n_bloques = [5,1]\n",
        "model = keras.Sequential()\n",
        "for bloque in range(n_bloques[0]):\n",
        "    model.add(Conv2D(filters = 128/(2*bloque),\n",
        "      kernel_size = (3,3),\n",
        "      strides=(1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      data_format=\"channels_last\"))\n",
        "    model.add( Conv2D(filters = 128/(2*bloque),\n",
        "      kernel_size = (3,3),\n",
        "      strides=(1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      data_format=\"channels_last\"))\n",
        "    model.add( MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=4, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=5)\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.19792187213897705\n",
            "Accuracy in test data: 0.9262899160385132\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "585/585 [==============================] - 1115s 2s/step - loss: 1.2674 - accuracy: 0.6300 - val_loss: 0.7430 - val_accuracy: 0.7018\n",
            "Epoch 2/2\n",
            "585/585 [==============================] - 1106s 2s/step - loss: 0.5594 - accuracy: 0.7852 - val_loss: 0.5700 - val_accuracy: 0.7866\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "n_bloques = [5,1]\n",
        "model = keras.Sequential()\n",
        "for bloque in range(n_bloques[1]):\n",
        "    model.add(Conv2D(filters = 128,\n",
        "      kernel_size = (3,3),\n",
        "      strides=(1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      data_format=\"channels_last\"))\n",
        "    model.add( Conv2D(filters = 128,\n",
        "      kernel_size = (3,3),\n",
        "      strides=(1, 1),\n",
        "      padding = 'same',\n",
        "      activation = 'relu',\n",
        "      data_format=\"channels_last\"))\n",
        "    model.add( MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=4, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=5)\n",
        "# ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 0.5762425661087036\n",
            "Accuracy in test data: 0.7936117649078369\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-HNQ18OpRzS"
      },
      "source": [
        "## 1.f Data Augmentation\n",
        "\n",
        "Otra manera de evitar sobreajuste y mejorar los desempeños de una red convolucional es usar aumentación de datos. La idea detrás de este método es un hecho muy simple: si rotamos ligeramente una foto por ejemplo de un caballo, seguirá siendo de un caballo. Lo mismo si la movemos ligeramente hacia algun lado, hacia arriba, etc.\n",
        "\n",
        "Keras trae implementado un generador de imágenes aumentadas como se muestra en el *código* a continuación. Explore a lo menos 4 variaciones del generador a continuación, la elección de los parámetros y sus respectivos valores queda en sus manos). Una vez generada la data aumentada, entrene la mejor red que haya obtenido a lo largo de toda la tarea.\n",
        "\n",
        "Pregunta: ¿Mejora el desempeño de la red utilizando aumentación de datos?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yLXVe-97pJQj"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Desktop\\2022-2\\ML\\Tarea 2\\Grape_disease_detection.ipynb Cell 94\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# datagen2.fit(X_train)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m modelD \u001b[39m=\u001b[39m model31(inputs, num_classes)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m modelD\u001b[39m.\u001b[39mfit(datagen2\u001b[39m.\u001b[39;49mflow(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m          subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m          validation_data\u001b[39m=\u001b[39mdatagen2\u001b[39m.\u001b[39mflow(X_val, y_val,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m          batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/2022-2/ML/Tarea%202/Grape_disease_detection.ipynb#Y144sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m          steps_per_epoch\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_train) \u001b[39m/\u001b[39m \u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\basti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:1370\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m   1317\u001b[0m          x,\n\u001b[0;32m   1318\u001b[0m          y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1326\u001b[0m          ignore_class_split\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1327\u001b[0m          subset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1328\u001b[0m   \u001b[39m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \n\u001b[0;32m   1330\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1370\u001b[0m   \u001b[39mreturn\u001b[39;00m NumpyArrayIterator(\n\u001b[0;32m   1371\u001b[0m       x,\n\u001b[0;32m   1372\u001b[0m       y,\n\u001b[0;32m   1373\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1374\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1375\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1376\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1377\u001b[0m       seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1378\u001b[0m       data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1379\u001b[0m       save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1380\u001b[0m       save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1381\u001b[0m       save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1382\u001b[0m       ignore_class_split\u001b[39m=\u001b[39;49mignore_class_split,\n\u001b[0;32m   1383\u001b[0m       subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1384\u001b[0m       dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n",
            "File \u001b[1;32mc:\\Users\\basti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    650\u001b[0m split_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39m*\u001b[39m image_data_generator\u001b[39m.\u001b[39m_validation_split)\n\u001b[0;32m    652\u001b[0m \u001b[39mif\u001b[39;00m (y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_class_split \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(\n\u001b[0;32m    653\u001b[0m     np\u001b[39m.\u001b[39munique(y[:split_idx]), np\u001b[39m.\u001b[39munique(y[split_idx:]))):\n\u001b[1;32m--> 654\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTraining and validation subsets \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    655\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mhave different number of classes after \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    656\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mthe split. If your numpy arrays are \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    657\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39msorted by the label, you might want \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    658\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mto shuffle them.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    660\u001b[0m \u001b[39mif\u001b[39;00m subset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    661\u001b[0m   x \u001b[39m=\u001b[39m x[:split_idx]\n",
            "\u001b[1;31mValueError\u001b[0m: Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them."
          ]
        }
      ],
      "source": [
        "# datagen = ImageDataGenerator(\n",
        "#         featurewise_center=...,  # set input mean to 0 over the dataset\n",
        "#         samplewise_center=...,  # set each sample mean to 0\n",
        "#         featurewise_std_normalization=...,  # divide inputs by std of the dataset\n",
        "#         samplewise_std_normalization=...,  # divide each input by its std\n",
        "#         zca_whitening=...,  # apply ZCA whitening\n",
        "#         rotation_range=...,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#         zoom_range = ..., # Randomly zoom image \n",
        "#         width_shift_range=...,  # randomly shift images horizontally (fraction of total width)\n",
        "#         height_shift_range=...,  # randomly shift images vertically (fraction of total height)\n",
        "#         horizontal_flip=...,  # randomly flip images\n",
        "#         vertical_flip=...)  # randomly flip images\n",
        "\n",
        "datagen2 = ImageDataGenerator(featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    brightness_range=None,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        ")\n",
        "\n",
        "\n",
        "# datagen2.fit(X_train)\n",
        "modelD = model31(inputs, num_classes)\n",
        "modelD.fit(datagen2.flow(X_train, y_train, batch_size=32,\n",
        "         subset='training'),\n",
        "         validation_data=datagen2.flow(X_val, y_val,\n",
        "         batch_size=4, subset='validation'),\n",
        "         steps_per_epoch=len(X_train) / 32, epochs=2)\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTBpC5H-pJvg"
      },
      "source": [
        "## 1.g Bloque Residual\n",
        "\n",
        "A continuación se probaran arquitecturas de red con conexiones residuales, puede usar la data aumentada si le parece indicado.\n",
        "\n",
        "<center><img src=\"https://production-media.paperswithcode.com/methods/resnet-e1548261477164.png\" width=\"300\"/></center>\n",
        "\n",
        "\n",
        "En la imagen se muestra el bloque básico de la arquitectura de la primera variación de la Red Residual: ResNet (https://arxiv.org/abs/1512.03385). Investigue las principales motivaciones de cómo implementar este tipo de red, sus ventajas, sus desventajas y luego cree y entrene una red con 1, 2, 3, 4 y 5 bloques residuales. ¿Como deben ser las dimensiones del input $x$ y de $\\mathcal{F}(x)$ para poder realizar la operación $\\mathcal{F}(x) + x$ entes del *relu* de más abajo?, ¿qué tipo de padding hay que usar en la convolución para mantener las mismas dimensiones de entrada y de salida?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "SEWeM2s3piLb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def relu_bn(inputs):\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x, filters, kernel_size): #-> Tensor\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= 1,#(1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    # ...\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=X_train.shape[1:])\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    num_blocks_list = [1]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        #...\n",
        "        t = residual_block(t,filters=num_filters,kernel_size = 3)\n",
        "        num_filters *= 2\n",
        "        #...\n",
        "    \n",
        "    t = MaxPooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(4, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "585/585 [==============================] - 830s 1s/step - loss: 28.2093 - accuracy: 0.7579 - val_loss: 39.2771 - val_accuracy: 0.7921\n",
            "Epoch 2/2\n",
            "585/585 [==============================] - 848s 1s/step - loss: 16.3746 - accuracy: 0.8676 - val_loss: 17.8712 - val_accuracy: 0.8495\n"
          ]
        }
      ],
      "source": [
        "modelresnet = create_res_net()\n",
        "my_callbacks = [History(), EarlyStopping(patience=10, min_delta=0.01, monitor='val_accuracy', mode=\"max\", restore_best_weights = True)]\n",
        "\n",
        "# Fit the model\n",
        "history = modelresnet.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in test data: 19.733539581298828\n",
            "Accuracy in test data: 0.8402948379516602\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = modelresnet.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Loss in test data: {test_loss}\\nAccuracy in test data: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5M-v8rSpj5J"
      },
      "source": [
        "## 1.h Bloque Inception\n",
        "\n",
        "En preguntas anteriores se pidió probar con distintos tamaños de kernel, en este tipo de bloque la idea es usar varios tamaños al mismo tiempo y así extraer características de contextos grandes y pequeños.\n",
        "\n",
        "Para comenzar es útil preguntarse: ¿Qué pasa si se desea modificar solamente el número de canales?. Existe una forma de mantener las dimensiones de entrada, modificando el número de canales de la salida: La convolución $1 \\times 1$.\n",
        "\n",
        "Imagine que tiene una matriz $M$ de tamaño $6 \\times 6$, si realiza una convolución con una matriz $m$ de $1\\times 1$ y luego una activación, entonces $M^{6 \\times 6} * m^{1\\times 1}$ será una multiplicación element-wise entre el valor de $m$ y cada elemento de $M$ resultando luego de la activación otra matriz de $6\\times 6$. \n",
        "\n",
        "Teniendo en mente lo anterior, suponga ahora que la entrada es un arreglo de tamaño $(6 \\times 6 \\times 32)$, es decir, tiene 32 canales. Considere que desea aplicar una convolución con $N$ filtros a todos los canales, entonces el tamaño de los filtros debe ser $(1\\times 1 \\times 32)$, el resultado de la convolución será tendrá un tamaño $(6 \\times 6 \\times N)$. Por lo tanto es posible aumentar, mantener o disminuir el la cantidad de canales de la salida. La idea de mantener los canales es aplicar una activación no lineal, lo que permite a la red aprender funciónes más complejas.\n",
        "\n",
        "Otra ventaja de la convolución $(1\\times 1)$ es que ayuda a reducir \n",
        "el costo computacional entre otras convoluciones, por ejemplo si se aplican 32 filtros de tamaño $(5\\times 5 \\times 192)$ con padding `same` a una entrada de tamaño $(28 \\times 28 \\times 192)$, entonces la salida será de tamaño $(28 \\times 28 \\times 32)$ y el total de multiplicaciones será: $28\\times 28 \\times 32 \\times 5 \\times 5 \\times 192 = 120\\; \\text{Millones}$. Por esta razón al aplicar convoluciones con filtros de distintos tamaños conviene reducir el número de operaciones a través de la siguiente idea llamada \"cuello de botella\":\n",
        "\n",
        "- A la entrada de $(28 \\times 28 \\times 192)$ aplique 16 filtros convolucionales de $(1 \\times 1 \\times 192)$, obteniendo una salida de $(28 \\times 28 \\times 16)$.\n",
        "\n",
        "- Luego aplique 32 filtros convolucionales de $(5 \\times 5 \\times 16)$, obteniendo una salida de $(28 \\times 28 \\times 32)$.\n",
        "\n",
        "Para la primera operación se requieren $28 \\times 28 \\times 16 \\times 192 = 2.4\\; \\text{Millones}$ de multiplicaciones, mientras que en la segunda son $28 \\times 28 \\times 32 \\times 5 \\times 5 \\times 16 = 10\\; \\text{Millones}$. Finalmente sumando ambas cantidades se obtiene un total de $12.4\\; \\text{Millones}$ de multiplicaciones, casi un 10% de lo que se obtiene al realizar la operación directamente!.\n",
        "\n",
        "Con todo lo anterior en mente se le pide que implemente una red con una red utilizando el bloque presentado en la imagen de abajo. Pruebe con 1,3 y 4 bloques antes de aplicar las capas densas. Note que en la imagen la entrada y la salida conservan la dimensión de $(28 \\times 28)$, por lo tanto entre cada bloque *inception* puede ir bajando dicha dimensión, para obtener más información sobre la construcción del bloque puede leer el siguiente documento https://arxiv.org/pdf/1409.4842.pdf.\n",
        "\n",
        "\n",
        "<center><img src=\"https://blog.kakaocdn.net/dn/dvyzrN/btqNkQRUokj/DrrKv0t5QJ9CyRI45aosd1/img.jpg\" width=\"300\"/><center/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5e3w6lrpv_R"
      },
      "source": [
        "## 1.i Transfer Learning\n",
        "\n",
        "A continuación se le pide escoger 1 modelo pre entrenado de entre los presentes en la siguiente lista https://keras.io/api/applications/, puede usar alguno de los vistos a lo largo de la tarea o puede escoger otro que le parezca. En el link anterior y en el siguiente puede encontrar información acerca de los modelos, su implementación y otras consideraciones.\n",
        "\n",
        "Preguntas: ¿Qué es Transfer Learning?, ¿Cómo se implementa Transfer Learning con un modelo pre entrenado? (explique brevemente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "kaljxP6fQ1UD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "293/293 [==============================] - 171s 571ms/step - loss: 0.7653 - val_loss: 0.2462\n",
            "Epoch 2/2\n",
            "293/293 [==============================] - 161s 551ms/step - loss: 0.3136 - val_loss: 0.2862\n",
            "0 input_8\n",
            "1 conv2d_26\n",
            "2 batch_normalization_16\n",
            "3 activation\n",
            "4 conv2d_27\n",
            "5 batch_normalization_17\n",
            "6 activation_1\n",
            "7 conv2d_28\n",
            "8 batch_normalization_18\n",
            "9 activation_2\n",
            "10 max_pooling2d_18\n",
            "11 conv2d_29\n",
            "12 batch_normalization_19\n",
            "13 activation_3\n",
            "14 conv2d_30\n",
            "15 batch_normalization_20\n",
            "16 activation_4\n",
            "17 max_pooling2d_19\n",
            "18 conv2d_34\n",
            "19 batch_normalization_24\n",
            "20 activation_8\n",
            "21 conv2d_32\n",
            "22 conv2d_35\n",
            "23 batch_normalization_22\n",
            "24 batch_normalization_25\n",
            "25 activation_6\n",
            "26 activation_9\n",
            "27 average_pooling2d\n",
            "28 conv2d_31\n",
            "29 conv2d_33\n",
            "30 conv2d_36\n",
            "31 conv2d_37\n",
            "32 batch_normalization_21\n",
            "33 batch_normalization_23\n",
            "34 batch_normalization_26\n",
            "35 batch_normalization_27\n",
            "36 activation_5\n",
            "37 activation_7\n",
            "38 activation_10\n",
            "39 activation_11\n",
            "40 mixed0\n",
            "41 conv2d_41\n",
            "42 batch_normalization_31\n",
            "43 activation_15\n",
            "44 conv2d_39\n",
            "45 conv2d_42\n",
            "46 batch_normalization_29\n",
            "47 batch_normalization_32\n",
            "48 activation_13\n",
            "49 activation_16\n",
            "50 average_pooling2d_1\n",
            "51 conv2d_38\n",
            "52 conv2d_40\n",
            "53 conv2d_43\n",
            "54 conv2d_44\n",
            "55 batch_normalization_28\n",
            "56 batch_normalization_30\n",
            "57 batch_normalization_33\n",
            "58 batch_normalization_34\n",
            "59 activation_12\n",
            "60 activation_14\n",
            "61 activation_17\n",
            "62 activation_18\n",
            "63 mixed1\n",
            "64 conv2d_48\n",
            "65 batch_normalization_38\n",
            "66 activation_22\n",
            "67 conv2d_46\n",
            "68 conv2d_49\n",
            "69 batch_normalization_36\n",
            "70 batch_normalization_39\n",
            "71 activation_20\n",
            "72 activation_23\n",
            "73 average_pooling2d_2\n",
            "74 conv2d_45\n",
            "75 conv2d_47\n",
            "76 conv2d_50\n",
            "77 conv2d_51\n",
            "78 batch_normalization_35\n",
            "79 batch_normalization_37\n",
            "80 batch_normalization_40\n",
            "81 batch_normalization_41\n",
            "82 activation_19\n",
            "83 activation_21\n",
            "84 activation_24\n",
            "85 activation_25\n",
            "86 mixed2\n",
            "87 conv2d_53\n",
            "88 batch_normalization_43\n",
            "89 activation_27\n",
            "90 conv2d_54\n",
            "91 batch_normalization_44\n",
            "92 activation_28\n",
            "93 conv2d_52\n",
            "94 conv2d_55\n",
            "95 batch_normalization_42\n",
            "96 batch_normalization_45\n",
            "97 activation_26\n",
            "98 activation_29\n",
            "99 max_pooling2d_20\n",
            "100 mixed3\n",
            "101 conv2d_60\n",
            "102 batch_normalization_50\n",
            "103 activation_34\n",
            "104 conv2d_61\n",
            "105 batch_normalization_51\n",
            "106 activation_35\n",
            "107 conv2d_57\n",
            "108 conv2d_62\n",
            "109 batch_normalization_47\n",
            "110 batch_normalization_52\n",
            "111 activation_31\n",
            "112 activation_36\n",
            "113 conv2d_58\n",
            "114 conv2d_63\n",
            "115 batch_normalization_48\n",
            "116 batch_normalization_53\n",
            "117 activation_32\n",
            "118 activation_37\n",
            "119 average_pooling2d_3\n",
            "120 conv2d_56\n",
            "121 conv2d_59\n",
            "122 conv2d_64\n",
            "123 conv2d_65\n",
            "124 batch_normalization_46\n",
            "125 batch_normalization_49\n",
            "126 batch_normalization_54\n",
            "127 batch_normalization_55\n",
            "128 activation_30\n",
            "129 activation_33\n",
            "130 activation_38\n",
            "131 activation_39\n",
            "132 mixed4\n",
            "133 conv2d_70\n",
            "134 batch_normalization_60\n",
            "135 activation_44\n",
            "136 conv2d_71\n",
            "137 batch_normalization_61\n",
            "138 activation_45\n",
            "139 conv2d_67\n",
            "140 conv2d_72\n",
            "141 batch_normalization_57\n",
            "142 batch_normalization_62\n",
            "143 activation_41\n",
            "144 activation_46\n",
            "145 conv2d_68\n",
            "146 conv2d_73\n",
            "147 batch_normalization_58\n",
            "148 batch_normalization_63\n",
            "149 activation_42\n",
            "150 activation_47\n",
            "151 average_pooling2d_4\n",
            "152 conv2d_66\n",
            "153 conv2d_69\n",
            "154 conv2d_74\n",
            "155 conv2d_75\n",
            "156 batch_normalization_56\n",
            "157 batch_normalization_59\n",
            "158 batch_normalization_64\n",
            "159 batch_normalization_65\n",
            "160 activation_40\n",
            "161 activation_43\n",
            "162 activation_48\n",
            "163 activation_49\n",
            "164 mixed5\n",
            "165 conv2d_80\n",
            "166 batch_normalization_70\n",
            "167 activation_54\n",
            "168 conv2d_81\n",
            "169 batch_normalization_71\n",
            "170 activation_55\n",
            "171 conv2d_77\n",
            "172 conv2d_82\n",
            "173 batch_normalization_67\n",
            "174 batch_normalization_72\n",
            "175 activation_51\n",
            "176 activation_56\n",
            "177 conv2d_78\n",
            "178 conv2d_83\n",
            "179 batch_normalization_68\n",
            "180 batch_normalization_73\n",
            "181 activation_52\n",
            "182 activation_57\n",
            "183 average_pooling2d_5\n",
            "184 conv2d_76\n",
            "185 conv2d_79\n",
            "186 conv2d_84\n",
            "187 conv2d_85\n",
            "188 batch_normalization_66\n",
            "189 batch_normalization_69\n",
            "190 batch_normalization_74\n",
            "191 batch_normalization_75\n",
            "192 activation_50\n",
            "193 activation_53\n",
            "194 activation_58\n",
            "195 activation_59\n",
            "196 mixed6\n",
            "197 conv2d_90\n",
            "198 batch_normalization_80\n",
            "199 activation_64\n",
            "200 conv2d_91\n",
            "201 batch_normalization_81\n",
            "202 activation_65\n",
            "203 conv2d_87\n",
            "204 conv2d_92\n",
            "205 batch_normalization_77\n",
            "206 batch_normalization_82\n",
            "207 activation_61\n",
            "208 activation_66\n",
            "209 conv2d_88\n",
            "210 conv2d_93\n",
            "211 batch_normalization_78\n",
            "212 batch_normalization_83\n",
            "213 activation_62\n",
            "214 activation_67\n",
            "215 average_pooling2d_6\n",
            "216 conv2d_86\n",
            "217 conv2d_89\n",
            "218 conv2d_94\n",
            "219 conv2d_95\n",
            "220 batch_normalization_76\n",
            "221 batch_normalization_79\n",
            "222 batch_normalization_84\n",
            "223 batch_normalization_85\n",
            "224 activation_60\n",
            "225 activation_63\n",
            "226 activation_68\n",
            "227 activation_69\n",
            "228 mixed7\n",
            "229 conv2d_98\n",
            "230 batch_normalization_88\n",
            "231 activation_72\n",
            "232 conv2d_99\n",
            "233 batch_normalization_89\n",
            "234 activation_73\n",
            "235 conv2d_96\n",
            "236 conv2d_100\n",
            "237 batch_normalization_86\n",
            "238 batch_normalization_90\n",
            "239 activation_70\n",
            "240 activation_74\n",
            "241 conv2d_97\n",
            "242 conv2d_101\n",
            "243 batch_normalization_87\n",
            "244 batch_normalization_91\n",
            "245 activation_71\n",
            "246 activation_75\n",
            "247 max_pooling2d_21\n",
            "248 mixed8\n",
            "249 conv2d_106\n",
            "250 batch_normalization_96\n",
            "251 activation_80\n",
            "252 conv2d_103\n",
            "253 conv2d_107\n",
            "254 batch_normalization_93\n",
            "255 batch_normalization_97\n",
            "256 activation_77\n",
            "257 activation_81\n",
            "258 conv2d_104\n",
            "259 conv2d_105\n",
            "260 conv2d_108\n",
            "261 conv2d_109\n",
            "262 average_pooling2d_7\n",
            "263 conv2d_102\n",
            "264 batch_normalization_94\n",
            "265 batch_normalization_95\n",
            "266 batch_normalization_98\n",
            "267 batch_normalization_99\n",
            "268 conv2d_110\n",
            "269 batch_normalization_92\n",
            "270 activation_78\n",
            "271 activation_79\n",
            "272 activation_82\n",
            "273 activation_83\n",
            "274 batch_normalization_100\n",
            "275 activation_76\n",
            "276 mixed9_0\n",
            "277 concatenate\n",
            "278 activation_84\n",
            "279 mixed9\n",
            "280 conv2d_115\n",
            "281 batch_normalization_105\n",
            "282 activation_89\n",
            "283 conv2d_112\n",
            "284 conv2d_116\n",
            "285 batch_normalization_102\n",
            "286 batch_normalization_106\n",
            "287 activation_86\n",
            "288 activation_90\n",
            "289 conv2d_113\n",
            "290 conv2d_114\n",
            "291 conv2d_117\n",
            "292 conv2d_118\n",
            "293 average_pooling2d_8\n",
            "294 conv2d_111\n",
            "295 batch_normalization_103\n",
            "296 batch_normalization_104\n",
            "297 batch_normalization_107\n",
            "298 batch_normalization_108\n",
            "299 conv2d_119\n",
            "300 batch_normalization_101\n",
            "301 activation_87\n",
            "302 activation_88\n",
            "303 activation_91\n",
            "304 activation_92\n",
            "305 batch_normalization_109\n",
            "306 activation_85\n",
            "307 mixed9_1\n",
            "308 concatenate_1\n",
            "309 activation_93\n",
            "310 mixed10\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "585/585 [==============================] - 252s 424ms/step - loss: 0.3974 - val_loss: 0.2062\n",
            "Epoch 2/2\n",
            "585/585 [==============================] - 226s 386ms/step - loss: 0.2512 - val_loss: 0.1385\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x240454f1a00>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=10)\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Transfer learnign utiliza redes anteriores entrenadas con grandes dataset y por ende con un conocimiento utilizable para casos especificos como en está tarea**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fLFE6XMBrHFe"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "48c0ee024c6cc2421e377eb4076cadf4ce6eb7a4584917e3645e162e32894617"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
